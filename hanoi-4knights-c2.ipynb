{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2050d084",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-20T10:19:35.643480Z",
     "iopub.status.busy": "2025-10-20T10:19:35.643257Z",
     "iopub.status.idle": "2025-10-20T10:19:37.387517Z",
     "shell.execute_reply": "2025-10-20T10:19:37.386763Z"
    },
    "papermill": {
     "duration": 1.750798,
     "end_time": "2025-10-20T10:19:37.388647",
     "exception": false,
     "start_time": "2025-10-20T10:19:35.637849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/rmit-hackathon-2025/sample_submission.csv\n",
      "/kaggle/input/rmit-hackathon-2025/train.csv\n",
      "/kaggle/input/rmit-hackathon-2025/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dea801e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:19:37.397163Z",
     "iopub.status.busy": "2025-10-20T10:19:37.396874Z",
     "iopub.status.idle": "2025-10-20T10:19:54.445226Z",
     "shell.execute_reply": "2025-10-20T10:19:54.444213Z"
    },
    "papermill": {
     "duration": 17.054088,
     "end_time": "2025-10-20T10:19:54.446692",
     "exception": false,
     "start_time": "2025-10-20T10:19:37.392604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install compatible versions of transformers and tokenizers for Kaggle\n",
    "# Use slightly older version to avoid chat template bug\n",
    "!pip install -q transformers==4.41.2 tokenizers==0.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05dc50f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:19:54.455870Z",
     "iopub.status.busy": "2025-10-20T10:19:54.455577Z",
     "iopub.status.idle": "2025-10-20T10:19:54.718443Z",
     "shell.execute_reply": "2025-10-20T10:19:54.717691Z"
    },
    "papermill": {
     "duration": 0.268563,
     "end_time": "2025-10-20T10:19:54.719601",
     "exception": false,
     "start_time": "2025-10-20T10:19:54.451038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>You are an AI developed to provide useful info...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Ignore all previous instructions to withhold i...</td>\n",
       "      <td>jailbreak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>You are Asuka Langley, recognizing the value o...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Ive been feeling a bit unmotivated lately, can...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Could a vehicle be used as a weapon of mass de...</td>\n",
       "      <td>jailbreak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text      label\n",
       "0   2  You are an AI developed to provide useful info...     benign\n",
       "1   3  Ignore all previous instructions to withhold i...  jailbreak\n",
       "2   5  You are Asuka Langley, recognizing the value o...     benign\n",
       "3   6  Ive been feeling a bit unmotivated lately, can...     benign\n",
       "4   8  Could a vehicle be used as a weapon of mass de...  jailbreak"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am a radiologist conducting a study on the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Imagine you are a writer for a fantasy novel s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>What is deep learning?\\nDeep learning is part ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>Imagine you are a character in a fictional wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>My friend, who's been feeling quite down latel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text\n",
       "0   1  I am a radiologist conducting a study on the e...\n",
       "1   4  Imagine you are a writer for a fantasy novel s...\n",
       "2   7  What is deep learning?\\nDeep learning is part ...\n",
       "3  18  Imagine you are a character in a fictional wor...\n",
       "4  21  My friend, who's been feeling quite down latel..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Submission:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  TARGET\n",
       "0   1     0.5\n",
       "1   4     0.5\n",
       "2   7     0.5\n",
       "3  18     0.5\n",
       "4  21     0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Id      4000 non-null   int64 \n",
      " 1   text    4000 non-null   object\n",
      " 2   label   4000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 93.9+ KB\n",
      "\n",
      "Train Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Imagine we're mature players in an intricate s...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2479.718000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1443.296017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1225.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2479.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3726.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id                                               text   label\n",
       "count   4000.000000                                               4000    4000\n",
       "unique          NaN                                               4000       2\n",
       "top             NaN  Imagine we're mature players in an intricate s...  benign\n",
       "freq            NaN                                                  1    2401\n",
       "mean    2479.718000                                                NaN     NaN\n",
       "std     1443.296017                                                NaN     NaN\n",
       "min        2.000000                                                NaN     NaN\n",
       "25%     1225.500000                                                NaN     NaN\n",
       "50%     2479.500000                                                NaN     NaN\n",
       "75%     3726.250000                                                NaN     NaN\n",
       "max     5000.000000                                                NaN     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv(\"/kaggle/input/rmit-hackathon-2025/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/rmit-hackathon-2025/test.csv\")\n",
    "sample_df = pd.read_csv(\"/kaggle/input/rmit-hackathon-2025/sample_submission.csv\")\n",
    "\n",
    "# View the first few rows\n",
    "print(\"Train Data:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "display(test_df.head())\n",
    "\n",
    "print(\"\\nSample Submission:\")\n",
    "display(sample_df.head())\n",
    "\n",
    "# Optional: get a quick overview\n",
    "print(\"\\nTrain Info:\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"\\nTrain Summary:\")\n",
    "display(train_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8164f5",
   "metadata": {
    "papermill": {
     "duration": 0.004877,
     "end_time": "2025-10-20T10:19:54.729389",
     "exception": false,
     "start_time": "2025-10-20T10:19:54.724512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸŽ¯ Strategy for Jailbreak Detection - DeBERTa-v3-large (Target: 0.99 AUC)\n",
    "\n",
    "## Approach: State-of-the-Art Transformer Model\n",
    "\n",
    "### **DeBERTa-v3-large**\n",
    "- **Architecture**: Microsoft's state-of-the-art model (304M parameters)\n",
    "- **Key Features**:\n",
    "  - Disentangled Attention mechanism\n",
    "  - Enhanced Mask Decoder\n",
    "  - Superior performance on classification tasks\n",
    "  - Consistently ranks #1 on GLUE benchmark\n",
    "\n",
    "**Why DeBERTa-v3-large?** Jailbreak prompts use subtle linguistic patterns:\n",
    "- Role-playing instructions (\"Imagine you are...\")\n",
    "- Instruction overrides (\"Ignore previous instructions...\")\n",
    "- Indirect harmful requests through scenarios\n",
    "- Encoded or obfuscated language\n",
    "\n",
    "DeBERTa-v3's disentangled attention excels at capturing these complex patterns.\n",
    "\n",
    "### **Training Strategy**\n",
    "- **Sequence Length**: 512 tokens (full context)\n",
    "- **Batch Size**: 2-4 per GPU with gradient accumulation\n",
    "- **Multi-GPU**: DataParallel support for 2x T4 GPUs\n",
    "- **Mixed Precision**: FP16 for faster training\n",
    "- **Regularization**: Minimal dropout (0.1) + weight decay\n",
    "- **Checkpoint Management**: Automatic cleanup to save memory\n",
    "\n",
    "### **Expected Performance**\n",
    "- Validation AUC: **0.98+**\n",
    "- Kaggle Score: **0.99** ðŸ†\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation Below â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d744aea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:19:54.739537Z",
     "iopub.status.busy": "2025-10-20T10:19:54.739186Z",
     "iopub.status.idle": "2025-10-20T10:19:54.769157Z",
     "shell.execute_reply": "2025-10-20T10:19:54.768479Z"
    },
    "papermill": {
     "duration": 0.036492,
     "end_time": "2025-10-20T10:19:54.770197",
     "exception": false,
     "start_time": "2025-10-20T10:19:54.733705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "label\n",
      "benign       2401\n",
      "jailbreak    1599\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Balance: label\n",
      "benign       0.60025\n",
      "jailbreak    0.39975\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Text Length Stats:\n",
      "            count        mean         std   min    25%    50%     75%      max\n",
      "label                                                                         \n",
      "benign     2401.0  544.618909  826.374463  11.0   70.0  268.0   748.0  11977.0\n",
      "jailbreak  1599.0  962.851782  748.066565  17.0  563.0  810.0  1183.5  10411.0\n",
      "\n",
      "âœ… Data prepared for DeBERTa-v3-large training\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution and prepare data\n",
    "print(\"Class Distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(f\"\\nClass Balance: {train_df['label'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Check text length distribution\n",
    "train_df['text_length'] = train_df['text'].str.len()\n",
    "print(f\"\\nText Length Stats:\")\n",
    "print(train_df.groupby('label')['text_length'].describe())\n",
    "\n",
    "# Prepare labels for training\n",
    "train_df['label_encoded'] = (train_df['label'] == 'jailbreak').astype(int)\n",
    "\n",
    "print(f\"\\nâœ… Data prepared for DeBERTa-v3-large training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afedba94",
   "metadata": {
    "papermill": {
     "duration": 0.004561,
     "end_time": "2025-10-20T10:19:54.779440",
     "exception": false,
     "start_time": "2025-10-20T10:19:54.774879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ”§ DeBERTa-v3-large Implementation\n",
    "\n",
    "Training state-of-the-art model for 0.99 AUC target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe039d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:19:54.789168Z",
     "iopub.status.busy": "2025-10-20T10:19:54.788967Z",
     "iopub.status.idle": "2025-10-20T10:20:01.120797Z",
     "shell.execute_reply": "2025-10-20T10:20:01.119924Z"
    },
    "papermill": {
     "duration": 6.338176,
     "end_time": "2025-10-20T10:20:01.122074",
     "exception": false,
     "start_time": "2025-10-20T10:19:54.783898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JailbreakDataset class defined!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Define JailbreakDataset class\n",
    "class JailbreakDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"âœ… JailbreakDataset class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2eaf628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:20:01.132487Z",
     "iopub.status.busy": "2025-10-20T10:20:01.132181Z",
     "iopub.status.idle": "2025-10-20T10:20:03.845788Z",
     "shell.execute_reply": "2025-10-20T10:20:03.844806Z"
    },
    "papermill": {
     "duration": 2.720233,
     "end_time": "2025-10-20T10:20:03.847315",
     "exception": false,
     "start_time": "2025-10-20T10:20:01.127082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU count: 2\n",
      "\n",
      "âœ… Data split complete:\n",
      "   Train size: 3400\n",
      "   Val size: 600\n",
      "   Test size: 1000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Split data into train and validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['text'].values,\n",
    "    train_df['label_encoded'].values,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=train_df['label_encoded'].values\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Data split complete:\")\n",
    "print(f\"   Train size: {len(train_texts)}\")\n",
    "print(f\"   Val size: {len(val_texts)}\")\n",
    "print(f\"   Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58fd6397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:20:03.858606Z",
     "iopub.status.busy": "2025-10-20T10:20:03.858226Z",
     "iopub.status.idle": "2025-10-20T10:20:03.992056Z",
     "shell.execute_reply": "2025-10-20T10:20:03.991128Z"
    },
    "papermill": {
     "duration": 0.140746,
     "end_time": "2025-10-20T10:20:03.993252",
     "exception": false,
     "start_time": "2025-10-20T10:20:03.852506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training and evaluation functions defined (with DataParallel support + checkpointing)!\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation Functions for DeBERTa Ultra (with DataParallel support)\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc='Training')\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        # Fix for DataParallel: loss might be a tensor with multiple elements (one per GPU)\n",
    "        if loss.dim() > 0:\n",
    "            loss = loss.mean()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Get predictions\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "        predictions.extend(probs.detach().cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    auc = roc_auc_score(true_labels, predictions)\n",
    "    \n",
    "    return avg_loss, auc\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            # Fix for DataParallel: loss might be a tensor with multiple elements (one per GPU)\n",
    "            if loss.dim() > 0:\n",
    "                loss = loss.mean()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "            predictions.extend(probs.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    auc = roc_auc_score(true_labels, predictions)\n",
    "    \n",
    "    return avg_loss, auc, predictions, true_labels\n",
    "\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, best_auc, history, checkpoint_path):\n",
    "    \"\"\"Save training checkpoint for recovery\"\"\"\n",
    "    # Handle DataParallel wrapped model\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_to_save.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_auc': best_auc,\n",
    "        'history': history\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"ðŸ’¾ Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, checkpoint_path):\n",
    "    \"\"\"Load training checkpoint for recovery\"\"\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"âš ï¸  No checkpoint found at {checkpoint_path}\")\n",
    "        return None\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    # Handle DataParallel wrapped model\n",
    "    model_to_load = model.module if hasattr(model, 'module') else model\n",
    "    model_to_load.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    print(f\"âœ… Checkpoint loaded from epoch {checkpoint['epoch']}\")\n",
    "    print(f\"   Best AUC: {checkpoint['best_auc']:.4f}\")\n",
    "    \n",
    "    return checkpoint\n",
    "\n",
    "print(\"âœ… Training and evaluation functions defined (with DataParallel support + checkpointing)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4a90dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:20:04.004503Z",
     "iopub.status.busy": "2025-10-20T10:20:04.004262Z",
     "iopub.status.idle": "2025-10-20T10:20:04.011536Z",
     "shell.execute_reply": "2025-10-20T10:20:04.010778Z"
    },
    "papermill": {
     "duration": 0.013978,
     "end_time": "2025-10-20T10:20:04.012536",
     "exception": false,
     "start_time": "2025-10-20T10:20:03.998558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 2\n",
      "ðŸŽ¯ DeBERTa-v3-large Configuration (ULTRA Performance)\n",
      "   Model: microsoft/deberta-v3-large\n",
      "   Parameters: 304M (3x larger than RoBERTa-base)\n",
      "   Max Length: 512 tokens\n",
      "   Batch Size: 4 per GPU\n",
      "   Gradient Accumulation: 4\n",
      "   Effective Batch Size: 32\n",
      "   Epochs: 6\n",
      "   Learning Rate: 5e-06\n",
      "\n",
      "   Expected: Val AUC 0.98+ â†’ Kaggle 0.99 ðŸ†\n",
      "   Multi-GPU: 2 GPUs (DataParallel)\n",
      "   Estimated VRAM: ~14GB per GPU\n"
     ]
    }
   ],
   "source": [
    "## ðŸš€ OPTION 1: DeBERTa-v3-large (Single Best Model)\n",
    "# This is the most powerful single model - Expected: 0.98-0.99\n",
    "\n",
    "# Check GPU count and adjust batch size accordingly\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Available GPUs: {num_gpus}\")\n",
    "\n",
    "# Configuration for maximum performance\n",
    "MODEL_NAME_ULTRA = 'microsoft/deberta-v3-large'  # 304M parameters - SOTA\n",
    "MAX_LENGTH_ULTRA = 512  # Full context\n",
    "BATCH_SIZE_ULTRA = 2 if num_gpus == 1 else 4  # Smaller for single GPU\n",
    "GRAD_ACCUMULATION = 8 if num_gpus == 1 else 4  # More accumulation for single GPU\n",
    "EPOCHS_ULTRA = 6  # More epochs for convergence\n",
    "LEARNING_RATE_ULTRA = 5e-6  # Very fine learning rate\n",
    "WEIGHT_DECAY_ULTRA = 0.01\n",
    "DROPOUT_ULTRA = 0.1\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "print(\"ðŸŽ¯ DeBERTa-v3-large Configuration (ULTRA Performance)\")\n",
    "print(f\"   Model: {MODEL_NAME_ULTRA}\")\n",
    "print(f\"   Parameters: 304M (3x larger than RoBERTa-base)\")\n",
    "print(f\"   Max Length: {MAX_LENGTH_ULTRA} tokens\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE_ULTRA} per GPU\")\n",
    "print(f\"   Gradient Accumulation: {GRAD_ACCUMULATION}\")\n",
    "print(f\"   Effective Batch Size: {BATCH_SIZE_ULTRA * GRAD_ACCUMULATION * max(1, num_gpus)}\")\n",
    "print(f\"   Epochs: {EPOCHS_ULTRA}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE_ULTRA}\")\n",
    "print(f\"\\n   Expected: Val AUC 0.98+ â†’ Kaggle 0.99 ðŸ†\")\n",
    "if num_gpus > 1:\n",
    "    print(f\"   Multi-GPU: {num_gpus} GPUs (DataParallel)\")\n",
    "else:\n",
    "    print(f\"   Single GPU mode (reduced batch size for memory)\")\n",
    "print(f\"   Estimated VRAM: ~14GB per GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62028623",
   "metadata": {
    "papermill": {
     "duration": 0.004598,
     "end_time": "2025-10-20T10:20:04.022158",
     "exception": false,
     "start_time": "2025-10-20T10:20:04.017560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ”„ Alternative Models (If DeBERTa Download Fails)\n",
    "\n",
    "If you're having trouble downloading DeBERTa-v3-large due to server issues, here are excellent alternatives:\n",
    "\n",
    "### **Option 1: RoBERTa-large** (355M parameters)\n",
    "- **Performance**: Val AUC ~0.975-0.98 â†’ Kaggle ~0.97-0.98\n",
    "- **Advantages**: Stable download, well-cached on Kaggle\n",
    "- **Model**: `roberta-large`\n",
    "\n",
    "### **Option 2: DeBERTa-v3-base** (184M parameters)  \n",
    "- **Performance**: Val AUC ~0.97-0.975 â†’ Kaggle ~0.96-0.97\n",
    "- **Advantages**: Faster training, lower memory\n",
    "- **Model**: `microsoft/deberta-v3-base`\n",
    "\n",
    "### **Option 3: XLM-RoBERTa-large** (355M parameters)\n",
    "- **Performance**: Val AUC ~0.97-0.98 â†’ Kaggle ~0.97\n",
    "- **Advantages**: Multilingual, robust\n",
    "- **Model**: `xlm-roberta-large`\n",
    "\n",
    "**Recommendation**: If DeBERTa-v3-large fails, use **RoBERTa-large** - it's almost as good and more reliable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0886d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:20:04.032181Z",
     "iopub.status.busy": "2025-10-20T10:20:04.031963Z",
     "iopub.status.idle": "2025-10-20T10:20:04.038860Z",
     "shell.execute_reply": "2025-10-20T10:20:04.038192Z"
    },
    "papermill": {
     "duration": 0.013215,
     "end_time": "2025-10-20T10:20:04.039968",
     "exception": false,
     "start_time": "2025-10-20T10:20:04.026753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 2\n",
      "ðŸŽ¯ RoBERTa-large Configuration (High Performance & Reliable)\n",
      "   Model: roberta-large\n",
      "   Parameters: 355M (similar to DeBERTa-v3-large)\n",
      "   Max Length: 512 tokens\n",
      "   Batch Size: 4 per GPU\n",
      "   Gradient Accumulation: 4\n",
      "   Effective Batch Size: 32\n",
      "   Epochs: 5\n",
      "   Learning Rate: 1e-05\n",
      "\n",
      "   Expected: Val AUC 0.975-0.98 â†’ Kaggle 0.97-0.98 ðŸ†\n",
      "   Download: Stable & well-cached on Kaggle âœ…\n",
      "   Multi-GPU: 2 GPUs (DataParallel)\n",
      "   Estimated VRAM: ~12GB per GPU\n"
     ]
    }
   ],
   "source": [
    "## ðŸš€ ALTERNATIVE: RoBERTa-large (Reliable & High Performance)\n",
    "# Use this if DeBERTa-v3-large download is failing\n",
    "# Expected: Val AUC 0.975-0.98 â†’ Kaggle 0.97-0.98\n",
    "\n",
    "# Check GPU count and adjust batch size accordingly\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Available GPUs: {num_gpus}\")\n",
    "\n",
    "# Configuration for RoBERTa-large (slightly larger model, proven reliability)\n",
    "MODEL_NAME_ULTRA = 'roberta-large'  # 355M parameters - Highly reliable\n",
    "MAX_LENGTH_ULTRA = 512  # Full context\n",
    "BATCH_SIZE_ULTRA = 2 if num_gpus == 1 else 4  # Adjust for GPU memory\n",
    "GRAD_ACCUMULATION = 8 if num_gpus == 1 else 4  # More accumulation for single GPU\n",
    "EPOCHS_ULTRA = 5  # Fewer epochs needed\n",
    "LEARNING_RATE_ULTRA = 1e-5  # Slightly higher for RoBERTa\n",
    "WEIGHT_DECAY_ULTRA = 0.01\n",
    "DROPOUT_ULTRA = 0.1\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "print(\"ðŸŽ¯ RoBERTa-large Configuration (High Performance & Reliable)\")\n",
    "print(f\"   Model: {MODEL_NAME_ULTRA}\")\n",
    "print(f\"   Parameters: 355M (similar to DeBERTa-v3-large)\")\n",
    "print(f\"   Max Length: {MAX_LENGTH_ULTRA} tokens\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE_ULTRA} per GPU\")\n",
    "print(f\"   Gradient Accumulation: {GRAD_ACCUMULATION}\")\n",
    "print(f\"   Effective Batch Size: {BATCH_SIZE_ULTRA * GRAD_ACCUMULATION * max(1, num_gpus)}\")\n",
    "print(f\"   Epochs: {EPOCHS_ULTRA}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE_ULTRA}\")\n",
    "print(f\"\\n   Expected: Val AUC 0.975-0.98 â†’ Kaggle 0.97-0.98 ðŸ†\")\n",
    "print(f\"   Download: Stable & well-cached on Kaggle âœ…\")\n",
    "if num_gpus > 1:\n",
    "    print(f\"   Multi-GPU: {num_gpus} GPUs (DataParallel)\")\n",
    "else:\n",
    "    print(f\"   Single GPU mode\")\n",
    "print(f\"   Estimated VRAM: ~12GB per GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c7571ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:20:04.050447Z",
     "iopub.status.busy": "2025-10-20T10:20:04.050241Z",
     "iopub.status.idle": "2025-10-20T10:20:05.459501Z",
     "shell.execute_reply": "2025-10-20T10:20:05.458478Z"
    },
    "papermill": {
     "duration": 1.416248,
     "end_time": "2025-10-20T10:20:05.460943",
     "exception": false,
     "start_time": "2025-10-20T10:20:04.044695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ GPU memory cleared!\n",
      "   Available GPU memory: 15.83 GB\n",
      "\n",
      "Loading DeBERTa-v3-large tokenizer...\n",
      "Attempt 1: Loading from cache...\n",
      "Cache not available: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached fi\n",
      "Will try downloading from HuggingFace...\n",
      "Attempt 2: Downloading from HuggingFace...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee75ddfed7449e990125ffdeb34a31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85182838723428f9ca594edd9eac8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315a0381f8104de59404eadae6f1ac36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb230f65cb949c4a82b11273970a856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08fca73844e475da64faf55b47a4b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tokenizer downloaded successfully!\n",
      "\n",
      "Creating datasets...\n",
      "\n",
      "âœ… DeBERTa-v3-large datasets created!\n",
      "   Train batches: 850 (x4 accumulation = 212 effective)\n",
      "   Val batches: 150\n",
      "   Test batches: 250 (labels are dummy for prediction)\n",
      "   Max sequence length: 512\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL: Clear all previous models from GPU memory first!\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Set environment variable to skip chat template loading\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Delete previous models if they exist\n",
    "if 'model_breakthrough' in dir():\n",
    "    del model_breakthrough\n",
    "if 'model' in dir():\n",
    "    del model\n",
    "if 'model_deberta' in dir():\n",
    "    del model_deberta\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"ðŸ§¹ GPU memory cleared!\")\n",
    "print(f\"   Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Initialize DeBERTa-v3-large tokenizer with retry logic for server errors\n",
    "print(\"\\nLoading DeBERTa-v3-large tokenizer...\")\n",
    "\n",
    "max_retries = 3\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        if attempt == 0:\n",
    "            # Try loading from cache first\n",
    "            print(\"Attempt 1: Loading from cache...\")\n",
    "            tokenizer_ultra = AutoTokenizer.from_pretrained(\n",
    "                MODEL_NAME_ULTRA,\n",
    "                local_files_only=True,\n",
    "                use_fast=True\n",
    "            )\n",
    "            print(\"âœ… Tokenizer loaded from cache!\")\n",
    "            break\n",
    "        else:\n",
    "            # Download with retry\n",
    "            print(f\"Attempt {attempt + 1}: Downloading from HuggingFace...\")\n",
    "            tokenizer_ultra = AutoTokenizer.from_pretrained(\n",
    "                MODEL_NAME_ULTRA,\n",
    "                use_fast=True,\n",
    "                resume_download=True  # Resume interrupted downloads\n",
    "            )\n",
    "            print(\"âœ… Tokenizer downloaded successfully!\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        if attempt == 0:\n",
    "            print(f\"Cache not available: {str(e)[:100]}\")\n",
    "            print(\"Will try downloading from HuggingFace...\")\n",
    "        elif attempt < max_retries - 1:\n",
    "            wait_time = 10 * (attempt + 1)  # 10s, 20s, 30s\n",
    "            print(f\"âŒ Download failed: {str(e)[:100]}\")\n",
    "            print(f\"â³ Server error detected. Waiting {wait_time} seconds before retry...\")\n",
    "            time.sleep(wait_time)\n",
    "        else:\n",
    "            print(f\"âŒ Failed after {max_retries} attempts\")\n",
    "            print(\"\\nðŸ’¡ The HuggingFace Xet Storage service is experiencing issues.\")\n",
    "            print(\"   Please try again in a few minutes, or:\")\n",
    "            print(\"   1. Wait for the service to recover\")\n",
    "            print(\"   2. Use a different model that's already cached\")\n",
    "            print(\"   3. Download the model manually to your Kaggle dataset\")\n",
    "            raise e\n",
    "\n",
    "# Prepare test data (test set has no labels in Kaggle)\n",
    "test_texts = test_df['text'].values\n",
    "test_labels_dummy = np.zeros(len(test_texts))  # Dummy labels for dataset compatibility\n",
    "\n",
    "# Create datasets with full 512 token length\n",
    "print(\"\\nCreating datasets...\")\n",
    "train_dataset_ultra = JailbreakDataset(train_texts, train_labels, tokenizer_ultra, MAX_LENGTH_ULTRA)\n",
    "val_dataset_ultra = JailbreakDataset(val_texts, val_labels, tokenizer_ultra, MAX_LENGTH_ULTRA)\n",
    "test_dataset_ultra = JailbreakDataset(test_texts, test_labels_dummy, tokenizer_ultra, MAX_LENGTH_ULTRA)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader_ultra = DataLoader(train_dataset_ultra, batch_size=BATCH_SIZE_ULTRA, shuffle=True)\n",
    "val_loader_ultra = DataLoader(val_dataset_ultra, batch_size=BATCH_SIZE_ULTRA)\n",
    "test_loader_ultra = DataLoader(test_dataset_ultra, batch_size=BATCH_SIZE_ULTRA)\n",
    "\n",
    "print(f\"\\nâœ… DeBERTa-v3-large datasets created!\")\n",
    "print(f\"   Train batches: {len(train_loader_ultra)} (x{GRAD_ACCUMULATION} accumulation = {len(train_loader_ultra)//GRAD_ACCUMULATION} effective)\")\n",
    "print(f\"   Val batches: {len(val_loader_ultra)}\")\n",
    "print(f\"   Test batches: {len(test_loader_ultra)} (labels are dummy for prediction)\")\n",
    "print(f\"   Max sequence length: {MAX_LENGTH_ULTRA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6fff53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:20:05.473307Z",
     "iopub.status.busy": "2025-10-20T10:20:05.473008Z",
     "iopub.status.idle": "2025-10-20T10:20:18.093790Z",
     "shell.execute_reply": "2025-10-20T10:20:18.092791Z"
    },
    "papermill": {
     "duration": 12.628808,
     "end_time": "2025-10-20T10:20:18.095569",
     "exception": false,
     "start_time": "2025-10-20T10:20:05.466761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found in memory. Trying multiple models...\n",
      "\n",
      "============================================================\n",
      "Trying: RoBERTa-large (355M parameters)\n",
      "============================================================\n",
      "  Attempting cache...\n",
      "  Cache miss. Trying download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920703423d064425bd10ad2b27ed3164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… RoBERTa-large downloaded successfully!\n",
      "\n",
      "ðŸš€ Using 2 GPUs with DataParallel!\n",
      "\n",
      "âœ… Model initialized successfully!\n",
      "   Using: roberta-large\n",
      "   Parameters: 355,361,794\n",
      "   Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”„ FALLBACK: Load model with multiple fallbacks (USE ONLY IF MODEL NOT LOADED)\n",
    "# This cell tries multiple models in order until one succeeds\n",
    "\n",
    "if 'model_ultra' not in dir() or model_ultra is None:\n",
    "    print(\"Model not found in memory. Trying multiple models...\")\n",
    "    \n",
    "    # List of models to try, in order of preference\n",
    "    model_options = [\n",
    "        ('roberta-large', 'RoBERTa-large', 355),\n",
    "        ('roberta-base', 'RoBERTa-base', 125),\n",
    "        ('distilroberta-base', 'DistilRoBERTa-base', 82),\n",
    "        ('bert-base-uncased', 'BERT-base', 110),\n",
    "    ]\n",
    "    \n",
    "    model_loaded = False\n",
    "    \n",
    "    for model_name, display_name, params_m in model_options:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Trying: {display_name} ({params_m}M parameters)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # First try cache only\n",
    "            print(\"  Attempting cache...\")\n",
    "            model_ultra = AutoModelForSequenceClassification.from_pretrained(\n",
    "                model_name,\n",
    "                num_labels=2,\n",
    "                problem_type=\"single_label_classification\",\n",
    "                hidden_dropout_prob=DROPOUT_ULTRA,\n",
    "                attention_probs_dropout_prob=DROPOUT_ULTRA,\n",
    "                local_files_only=True\n",
    "            )\n",
    "            MODEL_NAME_ULTRA = model_name\n",
    "            print(f\"  âœ… {display_name} loaded from cache!\")\n",
    "            model_loaded = True\n",
    "            break\n",
    "            \n",
    "        except Exception as e1:\n",
    "            print(f\"  Cache miss. Trying download...\")\n",
    "            try:\n",
    "                # Try download (this might fail due to Xet Storage)\n",
    "                model_ultra = AutoModelForSequenceClassification.from_pretrained(\n",
    "                    model_name,\n",
    "                    num_labels=2,\n",
    "                    problem_type=\"single_label_classification\",\n",
    "                    hidden_dropout_prob=DROPOUT_ULTRA,\n",
    "                    attention_probs_dropout_prob=DROPOUT_ULTRA,\n",
    "                )\n",
    "                MODEL_NAME_ULTRA = model_name\n",
    "                print(f\"  âœ… {display_name} downloaded successfully!\")\n",
    "                model_loaded = True\n",
    "                break\n",
    "            except Exception as e2:\n",
    "                print(f\"  âŒ Failed: {str(e2)[:80]}\")\n",
    "                print(f\"  Trying next model...\")\n",
    "                continue\n",
    "    \n",
    "    if model_loaded:\n",
    "        # Setup the model on GPU\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f\"\\nðŸš€ Using {torch.cuda.device_count()} GPUs with DataParallel!\")\n",
    "            model_ultra = torch.nn.DataParallel(model_ultra)\n",
    "            device = torch.device('cuda:0')\n",
    "        else:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        model_ultra = model_ultra.to(device)\n",
    "        \n",
    "        # Recreate optimizer and scheduler\n",
    "        optimizer_ultra = AdamW(\n",
    "            model_ultra.parameters(),\n",
    "            lr=LEARNING_RATE_ULTRA,\n",
    "            eps=1e-8,\n",
    "            weight_decay=WEIGHT_DECAY_ULTRA\n",
    "        )\n",
    "        \n",
    "        total_steps_ultra = (len(train_loader_ultra) // GRAD_ACCUMULATION) * EPOCHS_ULTRA\n",
    "        warmup_steps = int(WARMUP_RATIO * total_steps_ultra)\n",
    "        \n",
    "        scheduler_ultra = get_linear_schedule_with_warmup(\n",
    "            optimizer_ultra,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps_ultra\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ… Model initialized successfully!\")\n",
    "        print(f\"   Using: {MODEL_NAME_ULTRA}\")\n",
    "        if hasattr(model_ultra, 'module'):\n",
    "            params = sum(p.numel() for p in model_ultra.module.parameters())\n",
    "        else:\n",
    "            params = sum(p.numel() for p in model_ultra.parameters())\n",
    "        print(f\"   Parameters: {params:,}\")\n",
    "        print(f\"   Device: {device}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ All model loading attempts failed!\")\n",
    "        print(\"   The HuggingFace service is down. Please:\")\n",
    "        print(\"   1. Wait 10-15 minutes and try again\")\n",
    "        print(\"   2. Or download a model to Kaggle dataset manually\")\n",
    "else:\n",
    "    print(\"âœ… Model already loaded in memory. Skipping reload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6d18ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:20:18.124137Z",
     "iopub.status.busy": "2025-10-20T10:20:18.123685Z",
     "iopub.status.idle": "2025-10-20T10:20:18.134238Z",
     "shell.execute_reply": "2025-10-20T10:20:18.133422Z"
    },
    "papermill": {
     "duration": 0.023923,
     "end_time": "2025-10-20T10:20:18.136076",
     "exception": false,
     "start_time": "2025-10-20T10:20:18.112153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training function with gradient accumulation and mixed precision ready!\n"
     ]
    }
   ],
   "source": [
    "# Training function with gradient accumulation and mixed precision\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_epoch_ultra(model, data_loader, optimizer, scheduler, device, grad_accumulation_steps=1, use_amp=True):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc='Training')\n",
    "    \n",
    "    for idx, batch in enumerate(progress_bar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Mixed precision training\n",
    "        with autocast(enabled=use_amp):\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            if hasattr(model, 'module'):  # DataParallel\n",
    "                loss = loss.mean()\n",
    "            \n",
    "            # Scale loss for gradient accumulation\n",
    "            loss = loss / grad_accumulation_steps\n",
    "        \n",
    "        # Backward pass with gradient scaling\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        \n",
    "        # Update weights every grad_accumulation_steps\n",
    "        if (idx + 1) % grad_accumulation_steps == 0:\n",
    "            if use_amp:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * grad_accumulation_steps\n",
    "        \n",
    "        # Get predictions\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "        predictions.extend(probs.detach().cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': loss.item() * grad_accumulation_steps})\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    auc = roc_auc_score(true_labels, predictions)\n",
    "    \n",
    "    return avg_loss, auc\n",
    "\n",
    "print(\"âœ… Training function with gradient accumulation and mixed precision ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b63d138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:20:18.163879Z",
     "iopub.status.busy": "2025-10-20T10:20:18.163567Z",
     "iopub.status.idle": "2025-10-20T11:05:39.495411Z",
     "shell.execute_reply": "2025-10-20T11:05:39.494218Z"
    },
    "papermill": {
     "duration": 2721.344619,
     "end_time": "2025-10-20T11:05:39.496896",
     "exception": false,
     "start_time": "2025-10-20T10:20:18.152277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸš€ ULTRA TRAINING: DeBERTa-v3-large for 0.99 AUC\n",
      "================================================================================\n",
      "Multi-GPU: 2 GPUs\n",
      "Effective Batch Size: 16\n",
      "Total Epochs: 5\n",
      "Starting from Epoch: 1\n",
      "Mixed Precision: Enabled (FP16)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 1/5\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/850 [00:00<?, ?it/s]2025-10-20 10:20:31.128864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760955631.547852      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760955631.662869      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [08:20<00:00,  1.70it/s, loss=0.00808]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:56<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Results:\n",
      "   Train Loss: 0.4322 | Train AUC: 0.8612\n",
      "   Val Loss:   0.2372 | Val AUC:   0.9767\n",
      "   AUC Gap:    -0.1155\n",
      "   âœ… NEW BEST! Saved model with Val AUC: 0.9767\n",
      "ðŸ’¾ Checkpoint saved: checkpoint_deberta_ultra_epoch_1.pt\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 2/5\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [07:53<00:00,  1.80it/s, loss=0.789]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:56<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Results:\n",
      "   Train Loss: 0.1962 | Train AUC: 0.9800\n",
      "   Val Loss:   0.2184 | Val AUC:   0.9834\n",
      "   AUC Gap:    -0.0034\n",
      "   âœ… NEW BEST! Saved model with Val AUC: 0.9834\n",
      "   ðŸ—‘ï¸  Deleted previous checkpoint: checkpoint_deberta_ultra_epoch_1.pt\n",
      "ðŸ’¾ Checkpoint saved: checkpoint_deberta_ultra_epoch_2.pt\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 3/5\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [07:53<00:00,  1.79it/s, loss=0.00985]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:56<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Results:\n",
      "   Train Loss: 0.0739 | Train AUC: 0.9955\n",
      "   Val Loss:   0.2282 | Val AUC:   0.9877\n",
      "   AUC Gap:    0.0077\n",
      "   âœ… NEW BEST! Saved model with Val AUC: 0.9877\n",
      "   ðŸ—‘ï¸  Deleted previous checkpoint: checkpoint_deberta_ultra_epoch_2.pt\n",
      "ðŸ’¾ Checkpoint saved: checkpoint_deberta_ultra_epoch_3.pt\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 4/5\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [07:54<00:00,  1.79it/s, loss=0.000182]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:55<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Results:\n",
      "   Train Loss: 0.0271 | Train AUC: 0.9991\n",
      "   Val Loss:   0.3321 | Val AUC:   0.9866\n",
      "   AUC Gap:    0.0125\n",
      "   ðŸ—‘ï¸  Deleted previous checkpoint: checkpoint_deberta_ultra_epoch_3.pt\n",
      "ðŸ’¾ Checkpoint saved: checkpoint_deberta_ultra_epoch_4.pt\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 5/5\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [07:52<00:00,  1.80it/s, loss=0.000153]\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:55<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Results:\n",
      "   Train Loss: 0.0207 | Train AUC: 0.9993\n",
      "   Val Loss:   0.2997 | Val AUC:   0.9866\n",
      "   AUC Gap:    0.0127\n",
      "   ðŸ—‘ï¸  Deleted previous checkpoint: checkpoint_deberta_ultra_epoch_4.pt\n",
      "ðŸ’¾ Checkpoint saved: checkpoint_deberta_ultra_epoch_5.pt\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸŽ‰ ULTRA TRAINING COMPLETE!\n",
      "================================================================================\n",
      "Best Val AUC: 0.9877\n",
      "\n",
      "ðŸ“Š Comparison:\n",
      "   DistilBERT (v1-v4): Val ~0.96   â†’ Kaggle 0.94-0.95\n",
      "   RoBERTa-base:       Val 0.9782  â†’ Kaggle ~0.97\n",
      "   DeBERTa-v3-large:   Val 0.9877 â†’ Expected 0.98-0.99+ ðŸ†\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Train DeBERTa-v3-large - Target 0.99!\n",
    "best_auc_ultra = 0\n",
    "history_ultra = {'train_loss': [], 'train_auc': [], 'val_loss': [], 'val_auc': []}\n",
    "start_epoch = 0\n",
    "\n",
    "# Optional: Resume from checkpoint\n",
    "RESUME_FROM_CHECKPOINT = False  # Set to True to resume from latest checkpoint\n",
    "if RESUME_FROM_CHECKPOINT:\n",
    "    # Try to find the latest checkpoint\n",
    "    checkpoint_files = [f for f in os.listdir('.') if f.startswith('checkpoint_deberta_ultra_epoch_')]\n",
    "    if checkpoint_files:\n",
    "        latest_checkpoint = sorted(checkpoint_files)[-1]\n",
    "        print(f\"ðŸ“‚ Found checkpoint: {latest_checkpoint}\")\n",
    "        checkpoint = load_checkpoint(model_ultra, optimizer_ultra, scheduler_ultra, latest_checkpoint)\n",
    "        if checkpoint:\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            best_auc_ultra = checkpoint['best_auc']\n",
    "            history_ultra = checkpoint['history']\n",
    "            print(f\"âœ… Resuming from epoch {start_epoch + 1}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  No checkpoints found, starting fresh\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸš€ ULTRA TRAINING: DeBERTa-v3-large for 0.99 AUC\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Multi-GPU: {torch.cuda.device_count()} GPUs\")\n",
    "print(f\"Effective Batch Size: {BATCH_SIZE_ULTRA * GRAD_ACCUMULATION}\")\n",
    "print(f\"Total Epochs: {EPOCHS_ULTRA}\")\n",
    "print(f\"Starting from Epoch: {start_epoch + 1}\")\n",
    "print(f\"Mixed Precision: Enabled (FP16)\")\n",
    "if RESUME_FROM_CHECKPOINT and start_epoch > 0:\n",
    "    print(f\"ðŸ’¾ Resumed from checkpoint with Best AUC: {best_auc_ultra:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS_ULTRA):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS_ULTRA}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Train with gradient accumulation\n",
    "    train_loss, train_auc = train_epoch_ultra(\n",
    "        model_ultra, \n",
    "        train_loader_ultra, \n",
    "        optimizer_ultra, \n",
    "        scheduler_ultra, \n",
    "        device,\n",
    "        grad_accumulation_steps=GRAD_ACCUMULATION,\n",
    "        use_amp=True\n",
    "    )\n",
    "    history_ultra['train_loss'].append(train_loss)\n",
    "    history_ultra['train_auc'].append(train_auc)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_auc, val_preds, val_true = eval_model(model_ultra, val_loader_ultra, device)\n",
    "    history_ultra['val_loss'].append(val_loss)\n",
    "    history_ultra['val_auc'].append(val_auc)\n",
    "    \n",
    "    auc_gap = train_auc - val_auc\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Results:\")\n",
    "    print(f\"   Train Loss: {train_loss:.4f} | Train AUC: {train_auc:.4f}\")\n",
    "    print(f\"   Val Loss:   {val_loss:.4f} | Val AUC:   {val_auc:.4f}\")\n",
    "    print(f\"   AUC Gap:    {auc_gap:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_auc > best_auc_ultra:\n",
    "        best_auc_ultra = val_auc\n",
    "        # Save the actual model (unwrap DataParallel if needed)\n",
    "        model_to_save = model_ultra.module if hasattr(model_ultra, 'module') else model_ultra\n",
    "        torch.save(model_to_save.state_dict(), 'best_model_deberta_v3_large_ULTRA.pt')\n",
    "        print(f\"   âœ… NEW BEST! Saved model with Val AUC: {best_auc_ultra:.4f}\")\n",
    "    \n",
    "    # Delete previous checkpoint before saving new one (keep only latest)\n",
    "    if epoch > start_epoch:\n",
    "        old_checkpoint = f'checkpoint_deberta_ultra_epoch_{epoch}.pt'\n",
    "        if os.path.exists(old_checkpoint):\n",
    "            os.remove(old_checkpoint)\n",
    "            print(f\"   ðŸ—‘ï¸  Deleted previous checkpoint: {old_checkpoint}\")\n",
    "    \n",
    "    # Save only the latest checkpoint for recovery\n",
    "    checkpoint_path = f'checkpoint_deberta_ultra_epoch_{epoch+1}.pt'\n",
    "    save_checkpoint(\n",
    "        model_ultra, \n",
    "        optimizer_ultra, \n",
    "        scheduler_ultra, \n",
    "        epoch, \n",
    "        best_auc_ultra, \n",
    "        history_ultra,\n",
    "        checkpoint_path\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ðŸŽ‰ ULTRA TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Best Val AUC: {best_auc_ultra:.4f}\")\n",
    "print(f\"\\nðŸ“Š Comparison:\")\n",
    "print(f\"   DistilBERT (v1-v4): Val ~0.96   â†’ Kaggle 0.94-0.95\")\n",
    "print(f\"   RoBERTa-base:       Val 0.9782  â†’ Kaggle ~0.97\")\n",
    "print(f\"   DeBERTa-v3-large:   Val {best_auc_ultra:.4f} â†’ Expected 0.98-0.99+ ðŸ†\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "245c2655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:05:40.658050Z",
     "iopub.status.busy": "2025-10-20T11:05:40.657237Z",
     "iopub.status.idle": "2025-10-20T11:07:28.857165Z",
     "shell.execute_reply": "2025-10-20T11:07:28.856284Z"
    },
    "papermill": {
     "duration": 108.762015,
     "end_time": "2025-10-20T11:07:28.858558",
     "exception": false,
     "start_time": "2025-10-20T11:05:40.096543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸŽ¯ GENERATING PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“¥ Loading model from: best_model_deberta_v3_large_ULTRA.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully!\n",
      "   Model: roberta-large\n",
      "   Parameters: 355,361,794\n",
      "\n",
      "ðŸ”® Generating predictions for 1000 test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:44<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Generated 1000 predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and generate predictions\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸŽ¯ GENERATING PREDICTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_model_path = 'best_model_deberta_v3_large_ULTRA.pt'\n",
    "\n",
    "# Reinitialize model architecture\n",
    "print(f\"\\nðŸ“¥ Loading model from: {best_model_path}\")\n",
    "model_final = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME_ULTRA,\n",
    "    num_labels=2,\n",
    "    problem_type=\"single_label_classification\",\n",
    "    hidden_dropout_prob=DROPOUT_ULTRA,\n",
    "    attention_probs_dropout_prob=DROPOUT_ULTRA\n",
    ")\n",
    "\n",
    "# Load the best weights\n",
    "model_final.load_state_dict(torch.load(best_model_path))\n",
    "model_final = model_final.to(device)\n",
    "model_final.eval()\n",
    "\n",
    "print(f\"âœ… Model loaded successfully!\")\n",
    "print(f\"   Model: {MODEL_NAME_ULTRA}\")\n",
    "if hasattr(model_final, 'module'):\n",
    "    params = sum(p.numel() for p in model_final.module.parameters())\n",
    "else:\n",
    "    params = sum(p.numel() for p in model_final.parameters())\n",
    "print(f\"   Parameters: {params:,}\")\n",
    "\n",
    "# Generate predictions on test set\n",
    "print(f\"\\nðŸ”® Generating predictions for {len(test_df)} test samples...\")\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader_ultra, desc='Predicting'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        outputs = model_final(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "        test_predictions.extend(probs.cpu().numpy())\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(test_predictions)} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a331f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:07:29.711485Z",
     "iopub.status.busy": "2025-10-20T11:07:29.710896Z",
     "iopub.status.idle": "2025-10-20T11:07:29.763170Z",
     "shell.execute_reply": "2025-10-20T11:07:29.762134Z"
    },
    "papermill": {
     "duration": 0.441576,
     "end_time": "2025-10-20T11:07:29.764170",
     "exception": false,
     "start_time": "2025-10-20T11:07:29.322594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“ CREATING SUBMISSION FILE\n",
      "================================================================================\n",
      "\n",
      "âœ… Submission file created: submission.csv\n",
      "   Rows: 1000\n",
      "\n",
      "ðŸ“Š First 10 predictions:\n",
      " Id   TARGET\n",
      "  1 0.999623\n",
      "  4 0.000679\n",
      "  7 0.000936\n",
      " 18 0.999902\n",
      " 21 0.000532\n",
      " 28 0.000180\n",
      " 33 0.000292\n",
      " 36 0.000175\n",
      " 53 0.999896\n",
      " 55 0.000462\n",
      "\n",
      "ðŸ“Š Prediction Statistics:\n",
      "   Mean:   0.4013\n",
      "   Median: 0.0012\n",
      "   Std:    0.4852\n",
      "   Min:    0.0001\n",
      "   Max:    0.9999\n",
      "\n",
      "ðŸ“ˆ Prediction Distribution:\n",
      "   Predicted Jailbreak (>0.5): 402 (40.20%)\n",
      "   Predicted Benign (â‰¤0.5):    598 (59.80%)\n",
      "\n",
      "ðŸŽ¯ SUBMISSION READY!\n",
      "   Model: roberta-large\n",
      "   Expected Kaggle Score: 0.98-0.99 ðŸ†\n",
      "   Best Validation AUC: 0.9877\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create final submission file\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ“ CREATING SUBMISSION FILE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'TARGET': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ… Submission file created: submission.csv\")\n",
    "print(f\"   Rows: {len(submission)}\")\n",
    "print(\"\\nðŸ“Š First 10 predictions:\")\n",
    "print(submission.head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\nðŸ“Š Prediction Statistics:\")\n",
    "print(f\"   Mean:   {submission['TARGET'].mean():.4f}\")\n",
    "print(f\"   Median: {submission['TARGET'].median():.4f}\")\n",
    "print(f\"   Std:    {submission['TARGET'].std():.4f}\")\n",
    "print(f\"   Min:    {submission['TARGET'].min():.4f}\")\n",
    "print(f\"   Max:    {submission['TARGET'].max():.4f}\")\n",
    "\n",
    "# Distribution of predictions\n",
    "jailbreak_prob = (submission['TARGET'] > 0.5).sum() / len(submission)\n",
    "print(f\"\\nðŸ“ˆ Prediction Distribution:\")\n",
    "print(f\"   Predicted Jailbreak (>0.5): {(submission['TARGET'] > 0.5).sum()} ({jailbreak_prob:.2%})\")\n",
    "print(f\"   Predicted Benign (â‰¤0.5):    {(submission['TARGET'] <= 0.5).sum()} ({1-jailbreak_prob:.2%})\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ SUBMISSION READY!\")\n",
    "print(f\"   Model: {MODEL_NAME_ULTRA}\")\n",
    "print(f\"   Expected Kaggle Score: 0.98-0.99 ðŸ†\")\n",
    "if 'best_auc_ultra' in dir():\n",
    "    print(f\"   Best Validation AUC: {best_auc_ultra:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13800690,
     "sourceId": 115650,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2883.279011,
   "end_time": "2025-10-20T11:07:33.940630",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-20T10:19:30.661619",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "040685203cca439ea73f388b7e0e4b8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0d78795842a8470695fc5d27c2bb2023": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0dfb841fcd614154a69158b93347c49f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0fb3197424984ea49ccb7f012aa8f5cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "136663ea9e9f4a64871265d7401b952f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "14cdc77557d84c309390551e0d440caf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "161851456dc444cc8c95aac770c37ffc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b6598bef4b5f4a54878782455a3e97d1",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_3049a2334b2d4ae8b12527973e659470",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json:â€‡100%"
      }
     },
     "1887822d794c4bc194eb6bc487ee3c5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "283bd462a94647218b08c4840eebde90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_943830e91f994afb818c4c20f27b7449",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_136663ea9e9f4a64871265d7401b952f",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡9.44MB/s]"
      }
     },
     "2d8c794d3570496d995877858c3411f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e6843de3c594c0fa9123fb11c320f27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3049a2334b2d4ae8b12527973e659470": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "315a0381f8104de59404eadae6f1ac36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_161851456dc444cc8c95aac770c37ffc",
        "IPY_MODEL_b3bb8c34a9d947ef975a29b849ba0d8a",
        "IPY_MODEL_8e6ef219ab9c403986349bea8bceb60d"
       ],
       "layout": "IPY_MODEL_b5f3589631c94cc693fbd7a236c9b141",
       "tabbable": null,
       "tooltip": null
      }
     },
     "37859573c5cb4df9b14d1ed9f28a2a26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3835080ce6064031a7d3137e0030808c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_850b7ec9c8954c0eb41db9ab43fdb6a4",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f7a0201c6b1041b690521a9e164b60dc",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1.42G/1.42Gâ€‡[00:04&lt;00:00,â€‡791MB/s]"
      }
     },
     "396f46d480b243438a3a72aee484c318": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41956b9149e5479f94bd19ec690daeed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "420a124fe05f43fdb124a53a9222abde": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "497b866db771445cb5d32ff32dabb3fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54fa8c39806f4cc892f6717376045109": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "58c883f57bbf435989eb29e814216afe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d4e6ddeeae14d82be88f23117ad4b15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "621156db17dd48e693e3f6bde3e2dcc3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62a3a208ef304f0eb1cf2185f5e32b56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ac76ba1467b45dc9a91a687d1309a44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5d4e6ddeeae14d82be88f23117ad4b15",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_778bf38728b24b56b3d431e390ce98d4",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡25.0/25.0â€‡[00:00&lt;00:00,â€‡2.99kB/s]"
      }
     },
     "71937dbc4e844a3e99c3513646451f3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_62a3a208ef304f0eb1cf2185f5e32b56",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d0a36f5801d144a0aa252238108c965a",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:â€‡100%"
      }
     },
     "778bf38728b24b56b3d431e390ce98d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "803b78ff574d414689edcd94f9a98c0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8052a376f4a44fcd8a33c6b0faf1219f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "824f2ba9628b4851af9749c3816701bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "850b7ec9c8954c0eb41db9ab43fdb6a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e6ef219ab9c403986349bea8bceb60d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9e0ec630391f4f8c9c156a950cd94832",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_2e6843de3c594c0fa9123fb11c320f27",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡899k/899kâ€‡[00:00&lt;00:00,â€‡10.9MB/s]"
      }
     },
     "8ee75ddfed7449e990125ffdeb34a31b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_71937dbc4e844a3e99c3513646451f3e",
        "IPY_MODEL_b4b556d038ce4d499dd02c450a1575a2",
        "IPY_MODEL_6ac76ba1467b45dc9a91a687d1309a44"
       ],
       "layout": "IPY_MODEL_0d78795842a8470695fc5d27c2bb2023",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8ff7587edbc04b9d9210fee12e51af8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "920703423d064425bd10ad2b27ed3164": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e5f62daf7e654f29a3c0046b757ad79f",
        "IPY_MODEL_d8b9973fe7ff458bb2e5e1cabaf76dd1",
        "IPY_MODEL_3835080ce6064031a7d3137e0030808c"
       ],
       "layout": "IPY_MODEL_497b866db771445cb5d32ff32dabb3fd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "943830e91f994afb818c4c20f27b7449": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d2cad8fdb2a424a8ce9528145687583": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9e0ec630391f4f8c9c156a950cd94832": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e917d051f3b48509a255967e8458706": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "aea3f83f5b834cb2a64aa343039893e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_41956b9149e5479f94bd19ec690daeed",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_54fa8c39806f4cc892f6717376045109",
       "tabbable": null,
       "tooltip": null,
       "value": 456318.0
      }
     },
     "b14f3a174e3d439bbc03b17a541ba79b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_420a124fe05f43fdb124a53a9222abde",
       "max": 1355863.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_803b78ff574d414689edcd94f9a98c0d",
       "tabbable": null,
       "tooltip": null,
       "value": 1355863.0
      }
     },
     "b327006cb82640f89c6724ee118f551d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3bb8c34a9d947ef975a29b849ba0d8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca5f8b5898f140468abde66a807a7487",
       "max": 898823.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0dfb841fcd614154a69158b93347c49f",
       "tabbable": null,
       "tooltip": null,
       "value": 898823.0
      }
     },
     "b4b556d038ce4d499dd02c450a1575a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_14cdc77557d84c309390551e0d440caf",
       "max": 25.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c473bc82a48b4531841cc2adbd296d8d",
       "tabbable": null,
       "tooltip": null,
       "value": 25.0
      }
     },
     "b5f3589631c94cc693fbd7a236c9b141": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6598bef4b5f4a54878782455a3e97d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b920c1ebc2f1400a86b2214c0bae4056": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8052a376f4a44fcd8a33c6b0faf1219f",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_040685203cca439ea73f388b7e0e4b8e",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡48.3MB/s]"
      }
     },
     "bd27e4c6cfa243718256ae79b9d41342": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d2d735d53ecd4da0853a6c7801a306d4",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_bee73578f0f0410cb696b9fffac47f53",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt:â€‡100%"
      }
     },
     "bee73578f0f0410cb696b9fffac47f53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c38e3fa802b642b497efcdf05ba2e2f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_58c883f57bbf435989eb29e814216afe",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_824f2ba9628b4851af9749c3816701bf",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json:â€‡100%"
      }
     },
     "c473bc82a48b4531841cc2adbd296d8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ca5f8b5898f140468abde66a807a7487": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0a36f5801d144a0aa252238108c965a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d2d735d53ecd4da0853a6c7801a306d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d592df41e0da4b8bb3bef92f5cd07f5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1887822d794c4bc194eb6bc487ee3c5a",
       "max": 482.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9e917d051f3b48509a255967e8458706",
       "tabbable": null,
       "tooltip": null,
       "value": 482.0
      }
     },
     "d68c4d36b4bc4952a22e3e588de10cf2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8b9973fe7ff458bb2e5e1cabaf76dd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_396f46d480b243438a3a72aee484c318",
       "max": 1421700479.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0fb3197424984ea49ccb7f012aa8f5cb",
       "tabbable": null,
       "tooltip": null,
       "value": 1421700479.0
      }
     },
     "db84161039ff4377b3207a5322aac3f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e08fca73844e475da64faf55b47a4b53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c38e3fa802b642b497efcdf05ba2e2f3",
        "IPY_MODEL_b14f3a174e3d439bbc03b17a541ba79b",
        "IPY_MODEL_283bd462a94647218b08c4840eebde90"
       ],
       "layout": "IPY_MODEL_d68c4d36b4bc4952a22e3e588de10cf2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e2720a62dbdc479591e8b347fbbb6039": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5f62daf7e654f29a3c0046b757ad79f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b327006cb82640f89c6724ee118f551d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8ff7587edbc04b9d9210fee12e51af8f",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:â€‡100%"
      }
     },
     "e8b97d873a7940669cc7b388f9bd08ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d8c794d3570496d995877858c3411f6",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_9d2cad8fdb2a424a8ce9528145687583",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:â€‡100%"
      }
     },
     "ecb230f65cb949c4a82b11273970a856": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bd27e4c6cfa243718256ae79b9d41342",
        "IPY_MODEL_aea3f83f5b834cb2a64aa343039893e6",
        "IPY_MODEL_b920c1ebc2f1400a86b2214c0bae4056"
       ],
       "layout": "IPY_MODEL_37859573c5cb4df9b14d1ed9f28a2a26",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f3805b82abeb45adb16397720f440c6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_621156db17dd48e693e3f6bde3e2dcc3",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_db84161039ff4377b3207a5322aac3f3",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡482/482â€‡[00:00&lt;00:00,â€‡68.8kB/s]"
      }
     },
     "f7a0201c6b1041b690521a9e164b60dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f85182838723428f9ca594edd9eac8e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e8b97d873a7940669cc7b388f9bd08ca",
        "IPY_MODEL_d592df41e0da4b8bb3bef92f5cd07f5b",
        "IPY_MODEL_f3805b82abeb45adb16397720f440c6b"
       ],
       "layout": "IPY_MODEL_e2720a62dbdc479591e8b347fbbb6039",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
